<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat</title>
    <link rel="stylesheet" href="/frontend/style.css">
</head>
<body>
    <div id="chat-container">
        <div id="chat-box"></div>
        <div id="status-bar"></div>
        <div id="input-area">
            <input type="text" id="message-input" placeholder="メッセージを入力..." disabled>
            <button id="send-button" disabled>送信</button>
        </div>
    </div>

    <script>
        // DOM Elements
        const chatBox = document.getElementById('chat-box');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');
        const statusBar = document.getElementById('status-bar');

        // Web Audio API
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let audioQueue = [];
        let isPlaying = false;
        
        // State
        let currentAiMessageElement = null;
        let userName = "U"; // ユーザー名を固定

        // WebSocket Connection
        const ws = new WebSocket(`ws://${window.location.host}/ws`);

        ws.onopen = function() {
            console.log("[SYSTEM] WebSocket connection established.");
            set_status("AIの準備ができました。");
            enable_input();
        };

        ws.onmessage = function(event) {
            const message = JSON.parse(event.data);
            console.log("[RECEIVE]", message);
            
            switch (message.type) {
                case 'history':
                    append_message(message.data.name, message.data.content);
                    break;
                
                // --- ここからが修正箇所 ---
                case 'next_speaker':
                    const speakerName = message.data;
                    set_status(`＞ ${speakerName}が発言を考えています...`);
                    // 空のメッセージ要素を先行して作成
                    if (speakerName !== userName) {
                        currentAiMessageElement = append_message(speakerName, '');
                    }
                    break;
                // --- ここまでが修正箇所 ---

                case 'chunk':
                    // next_speakerで要素は作成済みのはずなので、ここでは更新に専念
                    update_ai_message(message.data.content);
                    break;
                case 'audio':
                    audioQueue.push(message.data);
                    play_from_queue();
                    break;
                case 'stream_end':
                    finish_ai_turn();
                    break;
            }
        };
        
        ws.onclose = function() {
            console.error("[SYSTEM] WebSocket connection closed.");
            set_status("サーバーとの接続が切れました。リロードしてください。");
            disable_input();
        }
        ws.onerror = function(error) {
            console.error("[SYSTEM] WebSocket error:", error);
            set_status("エラーが発生しました。");
            disable_input();
        }

        // UI Functions
        function set_status(text) {
            statusBar.textContent = text;
        }

        function enable_input() {
            messageInput.disabled = false;
            sendButton.disabled = false;
            set_status("メッセージを入力してください。");
            console.log("[UI] Input enabled.");
        }

        function disable_input(text = "") {
            messageInput.disabled = true;
            sendButton.disabled = true;
            if (text) set_status(text);
            console.log("[UI] Input disabled.");
        }

        function append_message(name, text) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('message');
            const isUser = name === userName;
            messageElement.classList.add(isUser ? 'user-message' : 'ai-message');
            
            messageElement.innerHTML = `<strong class="name">${name}</strong><p>${text}</p>`;
            chatBox.appendChild(messageElement);
            chatBox.scrollTop = chatBox.scrollHeight;
            return messageElement;
        }
        
        // --- ここからが修正箇所 ---
        function update_ai_message(chunk) {
            // currentAiMessageElementはnext_speakerイベントで作成されているはず
            if (currentAiMessageElement) {
                const p = currentAiMessageElement.querySelector('p');
                p.textContent += chunk;
                chatBox.scrollTop = chatBox.scrollHeight;
            } else {
                // フォールバック：万が一要素がなかった場合（最初のAIターンなど）
                console.warn("[UI] currentAiMessageElement not found. A new one may be created implicitly.");
            }
        }
        // --- ここまでが修正箇所 ---

        function finish_ai_turn() {
            console.log("[SYSTEM] AI turn finished.");
            currentAiMessageElement = null;
            enable_input();
        }

        // Audio Functions
        function play_from_queue() {
            if (isPlaying || audioQueue.length === 0) {
                return;
            }
            isPlaying = true;
            console.log(`[AUDIO] Starting playback. Queue size: ${audioQueue.length}`);
            
            const audioData = audioQueue.shift();
            const rawAudio = atob(audioData.audio);
            const samplerate = audioData.samplerate;
            const dtype = audioData.dtype;

            const buffer = new ArrayBuffer(rawAudio.length);
            const view = new Uint8Array(buffer);
            for (let i = 0; i < rawAudio.length; i++) {
                view[i] = rawAudio.charCodeAt(i);
            }
            
            let float32Array;
            if (dtype === 'int16') {
                 const int16Array = new Int16Array(buffer);
                 float32Array = new Float32Array(int16Array.length);
                 for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                 }
            } else if (dtype === 'float32') {
                 float32Array = new Float32Array(buffer);
            } else {
                 console.error("[AUDIO] Unsupported dtype:", dtype);
                 isPlaying = false;
                 play_from_queue();
                 return;
            }

            const audioBuffer = audioContext.createBuffer(1, float32Array.length, samplerate);
            audioBuffer.copyToChannel(float32Array, 0);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = () => {
                console.log("[AUDIO] Playback finished.");
                isPlaying = false;
                play_from_queue();
            };
            source.start();
        }

        // Event Listeners
        function sendMessage() {
            const message = messageInput.value;
            if (message && !messageInput.disabled) {
                console.log("[SEND]", message);
                ws.send(message);
                // ユーザー自身のメッセージを即時表示
                append_message(userName, message);
                messageInput.value = '';
                disable_input("＞ 次の話者を決めています...");
            }
        }

        sendButton.onclick = sendMessage;
        messageInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });

    </script>
</body>
</html>