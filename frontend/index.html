<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat</title>
    <link rel="stylesheet" href="/frontend/style.css">
    <link rel="icon" href="/frontend/icon.ico">
</head>

<body>
    <div id="main-container">
        <div id="chat-container">
            <div id="chat-box"></div>
            <div id="status-area"></div>
            <!-- ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒªã‚¢ -->
            <div id="preview-area"></div>
            <div id="input-area">
                <button id="attach-button" title="ç”»åƒã‚’æ·»ä»˜">ğŸ“</button>
                <input type="file" id="image-input" accept="image/*" style="display: none;">
                <input type="text" id="message-input" placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..." disabled>
                <button id="send-button" disabled>é€ä¿¡</button>
                <button id="mic-button" title="å¸¸æ™‚éŸ³å£°å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ" disabled>ğŸ¤</button>
                <button id="webcam-button" title="Webã‚«ãƒ¡ãƒ©ã®ON/OFF">ğŸ“·</button>
            </div>
        </div>
        <div id="right-panels-container">
            <div id="image-panel" data-state="empty">
                <img id="context-image" src="" alt="Chat Context Image" data-state="empty">
            </div>
            <div id="webcam-panel" data-state="off">
                <video id="webcam-video" autoplay playsinline muted></video>
                <!-- ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´UI -->
                <div id="webcam-controls">
                    <label for="scale-slider">é€ä¿¡ã‚µã‚¤ã‚º: <span id="scale-value">50</span>%</label>
                    <input type="range" id="scale-slider" min="10" max="100" value="50" step="5">
                </div>
            </div>
        </div>
    </div>

    <script>
        const chatBox = document.getElementById('chat-box');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');
        const micButton = document.getElementById('mic-button');
        const statusArea = document.getElementById('status-area');
        const imagePanel = document.getElementById('image-panel');
        const contextImage = document.getElementById('context-image');
        const attachButton = document.getElementById('attach-button');
        const imageInput = document.getElementById('image-input');
        const previewArea = document.getElementById('preview-area');
        const webcamButton = document.getElementById('webcam-button');
        const webcamPanel = document.getElementById('webcam-panel');
        const webcamVideo = document.getElementById('webcam-video');
        const scaleSlider = document.getElementById('scale-slider');
        const scaleValueLabel = document.getElementById('scale-value');


        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const ws = new WebSocket(`ws://${window.location.host}/ws`);

        let audioQueue = [], isPlaying = false, currentAiMessageElement = null, userName = "U";
        let mediaRecorder, audioChunks = [], stream;
        let isContinuousMode = false;
        let aiTurnFinished = true;
        let recognition;
        let userInputMode = 'browser_asr'; // 'ai', 'browser_asr', 'server_asr'
        let isFullAutoMode = false;
        let manualStop = false;
        let tempUserMessageElement = null;
        let attachedImage = null;
        let isWebcamOn = false;
        let webcamStream = null;
        // VAD (ç„¡éŸ³æ¤œå‡º) é–¢é€£
        let silenceDetectionTimer = null;
        let audioStreamSource = null;


        ws.onopen = () => { /* åˆæœŸåŒ–ã¯ onmessage ã® config ã§è¡Œã† */ };
        ws.onclose = () => { update_status("main", "ã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šãŒåˆ‡ã‚Œã¾ã—ãŸã€‚"); disable_input(true); }
        ws.onerror = (e) => { update_status("main", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"); disable_input(true); }


        ws.onmessage = (event) => {
            const message = JSON.parse(event.data);
            console.log("[RECEIVE]", message);

            switch (message.type) {
                case 'config':
                    userName = message.data.user_name;
                    userInputMode = message.data.user_input_mode;

                    if (userInputMode === 'ai') {
                        isFullAutoMode = true;
                        disable_input(true);
                        update_status("main", "ğŸ¤– å…¨è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...");
                        micButton.style.display = 'none';
                        sendButton.style.display = 'none';
                        attachButton.style.display = 'none';
                        webcamButton.style.display = 'none';
                        messageInput.placeholder = "å…¨è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§ã™";
                    } else {
                        micButton.style.display = 'flex';
                        if (userInputMode === 'browser_asr') {
                            initializeSpeechRecognition();
                            micButton.title = `å¸¸æ™‚éŸ³å£°å…¥åŠ› (ãƒ–ãƒ©ã‚¦ã‚¶èªè­˜)`;
                        } else {
                            micButton.title = `å¸¸æ™‚éŸ³å£°å…¥åŠ› (ã‚µãƒ¼ãƒãƒ¼èªè­˜)`;
                        }
                    }
                    console.log(`GUI Input mode set to: ${userInputMode}`);
                    break;

                case 'user_transcription':
                    // ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰èªè­˜çµæœãŒæ¥ãŸã‚‰UIã«è¡¨ç¤ºã™ã‚‹ã ã‘ã«ã™ã‚‹
                    remove_status('asr-server');
                    remove_temp_user_message();
                    if (message.data && message.data.trim()) {
                        append_message(userName, message.data);
                    }
                    break;
                case 'retry_audio_input':
                    console.log("ASR failed or empty. Retrying input.");
                    remove_status('asr-server');
                    remove_temp_user_message();
                    finish_ai_turn();
                    break;

                case 'history':
                    const content = message.data.content;
                    const textOnly = content.replace(/\n\(ç”»åƒæ·»ä»˜\)$/, "");
                    append_message(message.data.name, textOnly, null);
                    break;

                case 'next_speaker':
                    aiTurnFinished = false;

                    if (micButton.classList.contains('recording')) {
                        manualStop = true;
                        stopRecording();
                    }

                    remove_status('speaker-decision');
                    update_status('ai_thinking', `ğŸ§  ${message.data}ãŒç™ºè¨€ã‚’è€ƒãˆã¦ã„ã¾ã™...`);
                    if (message.data !== userName || isFullAutoMode) {
                        currentAiMessageElement = append_message(message.data, '');
                    }
                    break;

                case 'chunk':
                    update_ai_message(message.data.content);
                    break;

                case 'utterance_end':
                    remove_status('ai_thinking');
                    if (!isFullAutoMode) {
                        update_status('speaker-decision', 'â¡ï¸ æ¬¡ã®è©±è€…ã‚’æ±ºã‚ã¦ã„ã¾ã™...');
                    }
                    currentAiMessageElement = null;
                    break;

                case 'audio':
                    audioQueue.push(message.data);
                    if (!isPlaying) { play_from_queue(); }
                    break;

                case 'conversation_end':
                    finish_ai_turn();
                    break;

                case 'image':
                    imagePanel.dataset.state = 'loaded';
                    contextImage.src = message.url;
                    break;

                case 'status_update':
                    update_status(message.data.id, message.data.text);
                    break;
                case 'status_remove':
                    remove_status(message.data.id);
                    break;
            }
        };

        const initializeSpeechRecognition = () => {
            if (!("webkitSpeechRecognition" in window)) {
                alert("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚");
                micButton.disabled = true;
                return;
            }
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'ja-JP';

            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    } else {
                        interimTranscript += event.results[i][0].transcript;
                    }
                }

                update_temp_user_message(interimTranscript);

                if (finalTranscript) {
                    const trimmedTranscript = finalTranscript.trim();
                    manualStop = true;
                    recognition.abort();
                    sendUserMessage(trimmedTranscript);
                }
            };

            recognition.onend = () => {
                micButton.classList.remove('recording');
                micButton.textContent = isContinuousMode ? "ğŸ™ï¸" : "ğŸ¤";
                remove_temp_user_message();
                remove_status('main-prompt');

                if (manualStop) {
                    manualStop = false;
                    return;
                }

                if (isContinuousMode && aiTurnFinished && !isPlaying) {
                    setTimeout(() => startRecording(), 100);
                } else if (!isContinuousMode) {
                    enable_input();
                }
            };

            recognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
                if (event.error !== 'aborted') {
                    update_status('asr-failed', `éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`, 3000);
                }
            };
        };
        const update_status = (id, text, timeout = 0) => { let el = document.getElementById(id); if (!el) { el = document.createElement('div'); el.id = id; el.className = 'status-item'; statusArea.appendChild(el); } el.textContent = text; if (timeout > 0) { setTimeout(() => { if (el) el.remove(); }, timeout); } };
        const remove_status = (id) => { const el = document.getElementById(id); if (el) el.remove(); };
        const enable_input = (isManual = true) => {
            if (isFullAutoMode) return;
            messageInput.disabled = false;
            sendButton.disabled = false;
            micButton.disabled = false;
            attachButton.disabled = false;
            if (!isContinuousMode || isManual) { remove_status("main-prompt"); update_status("main-prompt", "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã¾ãŸã¯ãƒã‚¤ã‚¯ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"); }
        };
        const disable_input = (isError = false) => {
            messageInput.disabled = true;
            sendButton.disabled = true;
            micButton.disabled = true;
            if (!isFullAutoMode) remove_status("main-prompt");
        };

        const append_message = (name, text, imageSrc = null) => {
            const isUser = name === userName;
            const messageClass = (isUser && !isFullAutoMode) ? 'user-message' : 'ai-message';
            const el = document.createElement('div');
            el.classList.add('message', messageClass);
            let imageHTML = '';
            if (imageSrc) {
                imageHTML = `<img src="${imageSrc}" class="message-image" alt="æ·»ä»˜ç”»åƒ">`;
            }
            // ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã‚‚pã‚¿ã‚°ã¯ç”Ÿæˆã™ã‚‹ï¼ˆAIã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã®ãŸã‚ï¼‰
            el.innerHTML = `<strong class="name">${name}</strong>${imageHTML}<p>${text || ''}</p>`;
            chatBox.appendChild(el);
            chatBox.scrollTop = chatBox.scrollHeight;
            return el;
        };
        const update_ai_message = (chunk) => { if (currentAiMessageElement) { currentAiMessageElement.querySelector('p').textContent += chunk; chatBox.scrollTop = chatBox.scrollHeight; } };

        const create_temp_user_message = () => {
            if (tempUserMessageElement) return;
            tempUserMessageElement = document.createElement('div');
            tempUserMessageElement.classList.add('message', 'user-message', 'temp-message');
            tempUserMessageElement.innerHTML = `<strong class="name">${userName}</strong><p></p>`;
            chatBox.appendChild(tempUserMessageElement);
            chatBox.scrollTop = chatBox.scrollHeight;
        };
        const update_temp_user_message = (text) => {
            if (!tempUserMessageElement) create_temp_user_message();
            if (tempUserMessageElement) {
                tempUserMessageElement.querySelector('p').textContent = text;
                chatBox.scrollTop = chatBox.scrollHeight;
            }
        };
        const remove_temp_user_message = () => {
            if (tempUserMessageElement) {
                tempUserMessageElement.remove();
                tempUserMessageElement = null;
            }
        };

        const finish_ai_turn = () => {
            currentAiMessageElement = null;
            remove_status('ai_thinking');
            remove_status('speaker-decision');
            aiTurnFinished = true;

            // ã“ã®é–¢æ•°ã¯ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ¶å¾¡ã‚’æˆ»ã™ã€éš›ã®å”¯ä¸€ã®ã‚²ãƒ¼ãƒˆã‚­ãƒ¼ãƒ‘ãƒ¼ã€‚
            // ã©ã‚“ãªçŠ¶æ³ã§å‘¼ã°ã‚Œã¦ã‚‚ï¼ˆæ­£å¸¸çµ‚äº†ã€ãƒªãƒˆãƒ©ã‚¤è¦æ±‚ãªã©ï¼‰ã€
            // UIã‚’ä¸€åº¦ã‚¯ãƒªãƒ¼ãƒ³ãªã€Œå¾…æ©ŸçŠ¶æ…‹ã€ã«ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚
            // ã“ã‚Œã«ã‚ˆã‚Šã€å‰ã®éŒ²éŸ³ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®UIï¼ˆèµ¤ã„éŒ²éŸ³ã‚¢ã‚¤ã‚³ãƒ³ï¼‰ãŒæ®‹ã‚‹ã®ã‚’é˜²ãã€‚
            micButton.classList.remove('recording');
            micButton.textContent = isContinuousMode ? "ğŸ™ï¸" : "ğŸ¤";

            if (!isPlaying) {
                if (isContinuousMode) {
                    enable_input(false);
                    setTimeout(() => {
                        if (aiTurnFinished && !isPlaying) {
                            startRecording();
                        }
                    }, 500);
                } else {
                    enable_input(true);
                }
            }
        };

        const play_from_queue = () => {
            if (audioQueue.length === 0) {
                isPlaying = false;
                if (aiTurnFinished) {
                    if (isContinuousMode) {
                        enable_input(false);
                        setTimeout(() => {
                            if (aiTurnFinished && !isPlaying) {
                                startRecording();
                            }
                        }, 500);
                    } else {
                        enable_input(true);
                    }
                }
                return;
            }

            if (!isPlaying) {
                if (isContinuousMode && stream && userInputMode === 'server_asr') {
                    stream.getAudioTracks().forEach(track => track.enabled = false);
                    console.log("ğŸ¤ Mic Muted by AI speech (Server ASR)");
                }
            }

            isPlaying = true;
            const { audio, samplerate, dtype } = audioQueue.shift();
            const rawAudio = atob(audio); const buffer = new ArrayBuffer(rawAudio.length); const view = new Uint8Array(buffer); for (let i = 0; i < rawAudio.length; i++) view[i] = rawAudio.charCodeAt(i); let float32Array; if (dtype === 'int16') { const i16 = new Int16Array(buffer); float32Array = new Float32Array(i16.length); for (let i = 0; i < i16.length; i++) float32Array[i] = i16[i] / 32768.0; } else if (dtype === 'float32') { float32Array = new Float32Array(buffer); } else { isPlaying = false; play_from_queue(); return; } const audioBuffer = audioContext.createBuffer(1, float32Array.length, samplerate); audioBuffer.copyToChannel(float32Array, 0);
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = () => { isPlaying = false; play_from_queue(); };
            source.start();
        };

        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¸€æœ¬åŒ–
        const sendUserMessage = (message) => {
            const text = message || '';
            const image = attachedImage || null;
            let webcamCapture = null;

            if (isWebcamOn && webcamStream) {
                const video = webcamVideo;
                const canvas = document.createElement('canvas');
                const scale = parseInt(scaleSlider.value) / 100;
                const targetWidth = Math.round(video.videoWidth * scale);
                const targetHeight = Math.round(video.videoHeight * scale);
                canvas.width = targetWidth;
                canvas.height = targetHeight;
                canvas.getContext('2d').drawImage(video, 0, 0, targetWidth, targetHeight);
                webcamCapture = canvas.toDataURL('image/jpeg');
            }

            if (text.trim() || image || webcamCapture) {
                remove_temp_user_message();
                append_message(userName, text, image);
                ws.send(JSON.stringify({ text, image, webcam_capture: webcamCapture }));
                disable_input();
                update_status('speaker-decision', 'â¡ï¸ æ¬¡ã®è©±è€…ã‚’æ±ºã‚ã¦ã„ã¾ã™...');
                clearAttachment();
            }
        };

        const handleTextInput = () => {
            const message = messageInput.value;
            if ((message && !messageInput.disabled) || attachedImage) {
                sendUserMessage(message);
                messageInput.value = '';
            }
        };

        const handleImageAttachment = (event) => {
            const file = event.target.files[0];
            if (!file) return;
            const reader = new FileReader();
            reader.onload = (e) => {
                attachedImage = e.target.result;
                previewArea.innerHTML = `
                    <div class="preview-container">
                        <img src="${attachedImage}" class="image-preview" alt="Preview"/>
                        <button class="remove-preview-btn">Ã—</button>
                    </div>`;
                previewArea.querySelector('.remove-preview-btn').onclick = clearAttachment;
            };
            reader.readAsDataURL(file);
            imageInput.value = '';
        };
        const clearAttachment = () => {
            attachedImage = null;
            previewArea.innerHTML = '';
        };

        const startRecording = async () => {
            if (isFullAutoMode || micButton.classList.contains('recording')) return;
            manualStop = false;
            messageInput.disabled = true;
            sendButton.disabled = true;

            micButton.classList.add('recording');
            micButton.textContent = "â¹ï¸";
            update_status('main-prompt', 'ğŸ¤ è©±ã—ã¦ãã ã•ã„...');

            if (userInputMode === 'browser_asr') {
                if (!recognition) { console.error("Recognition not initialized."); return; }
                try {
                    if (audioContext.state === 'suspended') { await audioContext.resume(); }
                    create_temp_user_message();
                    recognition.start();
                } catch (e) {
                    console.warn("Recognition might be already active:", e);
                }
            } else if (userInputMode === 'server_asr') {
                try {
                    if (audioContext.state === 'suspended') { await audioContext.resume(); }

                    if (!stream || !stream.active) {
                        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    }

                    if (stream.getAudioTracks().some(track => !track.enabled)) {
                        stream.getAudioTracks().forEach(track => { track.enabled = true; });
                        console.log("ğŸ¤ Mic Unmuted for recording (Server ASR)");
                    }

                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                    audioChunks = [];
                    mediaRecorder.ondataavailable = event => { audioChunks.push(event.data); };
                    mediaRecorder.onstop = () => {
                        if (silenceDetectionTimer) {
                            cancelAnimationFrame(silenceDetectionTimer);
                            silenceDetectionTimer = null;
                        }
                        if (audioStreamSource) {
                            audioStreamSource.disconnect();
                            audioStreamSource = null;
                        }

                        if (manualStop) {
                            manualStop = false;
                            return;
                        }

                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        audioChunks = [];

                        if (audioBlob.size > 1000) {
                            ws.send(audioBlob);
                            disable_input();
                            create_temp_user_message();
                            update_status('asr-server', 'ã‚µãƒ¼ãƒãƒ¼ã§éŸ³å£°ã‚’èªè­˜ä¸­...');
                        } else {
                            // ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã‚‹å ´åˆ(VADèª¤ä½œå‹•ãªã©)ã¯ã€ãã®ã¾ã¾å†é–‹
                            remove_temp_user_message();
                            if (isContinuousMode) {
                                setTimeout(startRecording, 100);
                            } else {
                                enable_input();
                            }
                        }
                    };
                    mediaRecorder.start();

                    if (isContinuousMode) {
                        audioStreamSource = audioContext.createMediaStreamSource(stream);
                        const analyser = audioContext.createAnalyser();
                        analyser.fftSize = 512;
                        audioStreamSource.connect(analyser);

                        const bufferLength = analyser.frequencyBinCount;
                        const dataArray = new Uint8Array(bufferLength);
                        let silentSince = Date.now();
                        const SILENCE_THRESHOLD = 5; // éŸ³é‡ã®ã—ãã„å€¤(0-255)ã€‚ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã€‚
                        const VAD_HANGOVER_MS = 1500; // ã“ã®æ™‚é–“(ms)ç„¡éŸ³ãŒç¶šã„ãŸã‚‰ç™ºè©±çµ‚äº†ã¨ã¿ãªã™

                        const detectSilence = () => {
                            analyser.getByteFrequencyData(dataArray);
                            const avg = dataArray.reduce((acc, val) => acc + val, 0) / bufferLength;

                            if (avg < SILENCE_THRESHOLD) {
                                if (Date.now() - silentSince > VAD_HANGOVER_MS) {
                                    if (mediaRecorder && mediaRecorder.state === "recording") {
                                        mediaRecorder.stop(); // onstopã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç«ã—é€ä¿¡ã•ã‚Œã‚‹
                                    }
                                    return;
                                }
                            } else {
                                silentSince = Date.now();
                            }
                            silenceDetectionTimer = requestAnimationFrame(detectSilence);
                        };
                        detectSilence();
                    }

                } catch (err) {
                    console.error("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:", err);
                    update_status('main-prompt', 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚');
                    enable_input();
                    micButton.classList.remove('recording');
                    micButton.textContent = "ğŸ¤";
                }
            }
        };

        const stopRecording = () => {
            micButton.classList.remove('recording');
            micButton.textContent = isContinuousMode ? "ğŸ™ï¸" : "ğŸ¤";
            remove_temp_user_message();
            remove_status('main-prompt');

            if (silenceDetectionTimer) {
                cancelAnimationFrame(silenceDetectionTimer);
                silenceDetectionTimer = null;
            }
            if (audioStreamSource) {
                audioStreamSource.disconnect();
                audioStreamSource = null;
            }

            if (userInputMode === 'browser_asr') {
                if (recognition) {
                    recognition.abort();
                }
            } else if (userInputMode === 'server_asr') {
                if (mediaRecorder && mediaRecorder.state === "recording") {
                    mediaRecorder.stop();
                }
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                }
            }
        };

        const startWebcam = async () => {
            try {
                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    webcamStream = await navigator.mediaDevices.getUserMedia({ video: true });
                    webcamVideo.srcObject = webcamStream;
                    webcamPanel.dataset.state = 'on';
                    webcamButton.classList.add('on');
                    isWebcamOn = true;
                } else {
                    update_status('webcam-error', 'ã‚«ãƒ¡ãƒ©æ©Ÿèƒ½ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚', 3000);
                }
            } catch (err) {
                update_status('webcam-error', 'ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚', 3000);
                console.error("Webã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:", err);
            }
        };

        const stopWebcam = () => {
            if (webcamStream) {
                webcamStream.getTracks().forEach(track => track.stop());
            }
            webcamStream = null;
            webcamVideo.srcObject = null;
            webcamPanel.dataset.state = 'off';
            webcamButton.classList.remove('on');
            isWebcamOn = false;
        };


        micButton.onclick = () => {
            if (isFullAutoMode) return;
            isContinuousMode = !isContinuousMode;
            micButton.classList.toggle('continuous-mode', isContinuousMode);
            if (isContinuousMode) {
                if (!micButton.classList.contains('recording') && !isPlaying) {
                    startRecording();
                }
            } else {
                if (micButton.classList.contains('recording')) {
                    manualStop = true;
                    stopRecording();
                }
                enable_input();
            }
        };

        webcamButton.onclick = () => {
            if (isWebcamOn) {
                stopWebcam();
            } else {
                startWebcam();
            }
        };

        scaleSlider.addEventListener('input', (e) => {
            scaleValueLabel.textContent = e.target.value;
        });


        sendButton.onclick = handleTextInput;
        messageInput.addEventListener('keypress', (e) => { if (e.key === 'Enter') handleTextInput() });
        attachButton.onclick = () => imageInput.click();
        imageInput.onchange = handleImageAttachment;
    </script>
</body>

</html>