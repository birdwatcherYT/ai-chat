import asyncio
import base64
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
from invoke.config import Config
import yaml
import traceback

from dotenv import load_dotenv

load_dotenv()

# æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.tts.base import TextToSpeech
from src.tts.voicevox import VoiceVox
from src.tts.coeiroink import CoeiroInk
from src.tts.aivisspeech import AivisSpeech
from src.lmm.common import LLMConfig, history_to_text
from src.lmm.llm import LLMs

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®è¨­å®š ---
app = FastAPI()
cfg = None
llmcfg = None
llms = None
engines = {}
ai_config = {}
history = []

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã®ãŸã‚ã®ã‚­ãƒ¥ãƒ¼
llm_text_queue = asyncio.Queue()
audio_data_queue = asyncio.Queue()


# --- åˆæœŸåŒ–å‡¦ç† ---
def load_config_and_init():
    global cfg, llmcfg, llms, engines, ai_config, history
    try:
        with open("invoke-utf8.yaml", "r", encoding="utf-8") as f:
            config_data = yaml.safe_load(f)
        cfg = Config(config_data)

        llmcfg = LLMConfig(cfg)
        llms = LLMs(llmcfg)

        engines = {
            "voicevox": VoiceVox(),
            "coeiroink": CoeiroInk(),
            "aivisspeech": AivisSpeech(),
        }
        ai_config = {ai["name"]: ai["voice"] for ai in cfg.chat.ai}

        history = [
            {
                "name": llmcfg.format(item["name"]),
                "content": llmcfg.format(item["content"]),
            }
            for item in cfg.chat.initial_message
        ]
        print("âœ… [SYSTEM] è¨­å®šã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ [SYSTEM] åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()


# --- WebSocketã®æ¥ç¶šç®¡ç† ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        print("âœ… [SYSTEM] ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ¥ç¶šã—ã¾ã—ãŸã€‚")

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
        print("ğŸ”Œ [SYSTEM] ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸã€‚")

    async def send_json(self, data: dict):
        if self.active_connections:
            try:
                await self.active_connections[0].send_json(data)
            except Exception as e:
                print(f"âŒ [SYSTEM] WebSocketé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")


manager = ConnectionManager()

# --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ¯ãƒ¼ã‚«ãƒ¼å®šç¾© ---


# LLMã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã€ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼
async def llm_stream_producer(turn: str):
    global history
    print(f"ğŸ§  [AI] '{turn}'ã®ç™ºè¨€ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    full_response = ""
    answer_segment = ""

    utter_chain = llms.get_utter_chain()
    utter_prompt_vars = {"speaker": turn, "messages": history_to_text(history)}

    try:
        for chunk in utter_chain.stream(utter_prompt_vars):
            chunk_content = chunk.content
            full_response += chunk_content
            answer_segment += chunk_content
            await manager.send_json(
                {"type": "chunk", "data": {"name": turn, "content": chunk_content}}
            )

            if answer_segment and answer_segment[-1] in cfg.chat.streaming_voice_output:
                print(
                    f"ğŸ“¦ [AI] ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆæˆã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥: '{answer_segment[:20]}...'"
                )
                await llm_text_queue.put((turn, answer_segment))
                answer_segment = ""

        if answer_segment:
            print(
                f"ğŸ“¦ [AI] æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆæˆã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥: '{answer_segment[:20]}...'"
            )
            await llm_text_queue.put((turn, answer_segment))

        history.append({"name": turn, "content": full_response})
        print(f"ğŸ“ [AI] '{turn}'ã®ç™ºè¨€ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"âŒ [AI] LLMãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ã§ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
    finally:
        await llm_text_queue.put(None)  # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ‚äº†ã‚·ã‚°ãƒŠãƒ«


# ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°åˆæˆã—ã€éŸ³å£°ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼
async def synthesis_consumer():
    print("ğŸ”Š [SYSTEM] éŸ³å£°åˆæˆãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    while True:
        task = await llm_text_queue.get()
        if task is None:
            await audio_data_queue.put(None)
            break

        speaker_name, text = task
        print(f"ğŸ™ï¸ [SYNTH] åˆæˆé–‹å§‹: [{speaker_name}] '{text[:20]}...'")
        voice_config = ai_config.get(speaker_name)
        if not voice_config or not voice_config.get("engine"):
            continue

        tts_engine: TextToSpeech = engines[voice_config["engine"]]
        try:
            data, sr = await tts_engine.synthesize_async(text, **voice_config["config"])
            if data is not None and sr is not None:
                await audio_data_queue.put((data, sr, str(data.dtype)))
                print(f"ğŸ¤ [SYNTH] åˆæˆæˆåŠŸã€éŸ³å£°ã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥ã€‚")
        except Exception as e:
            print(f"âŒ [SYNTH] éŸ³å£°åˆæˆã§ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
    print("â›” [SYSTEM] éŸ³å£°åˆæˆãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†ã—ã¾ã™ã€‚")


# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ã™ã‚‹ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼
async def audio_sender_consumer():
    print("ğŸ“¡ [SYSTEM] éŸ³å£°é€ä¿¡ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    while True:
        task = await audio_data_queue.get()
        if task is None:
            await manager.send_json({"type": "stream_end"})
            break

        data, sr, dtype = task
        try:
            encoded_audio = base64.b64encode(data.tobytes()).decode("utf-8")
            await manager.send_json(
                {
                    "type": "audio",
                    "data": {"audio": encoded_audio, "samplerate": sr, "dtype": dtype},
                }
            )
            print(f"âœ… [SEND] éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"âŒ [SEND] éŸ³å£°é€ä¿¡ã§ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
    print("â›” [SYSTEM] éŸ³å£°é€ä¿¡ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†ã—ã¾ã™ã€‚")


# --- WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    global history

    # æ¥ç¶šæ™‚ã«ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’é€ä¿¡
    for message in history:
        await websocket.send_json({"type": "history", "data": message})

    try:
        # æœ€åˆã®ã‚¿ãƒ¼ãƒ³ãŒAIãªã‚‰å®Ÿè¡Œ
        initial_turn = llmcfg.format(cfg.chat.initial_turn)
        if initial_turn != llmcfg.user_name:
            await manager.send_json({"type": "next_speaker", "data": initial_turn})
            asyncio.create_task(run_ai_pipeline(initial_turn))

        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¾…ã¤
        while True:
            user_message = await websocket.receive_text()
            print(f"ğŸ‘¤ [USER] å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: '{user_message}'")

            user_name = llmcfg.user_name
            history.append({"name": user_name, "content": user_message})

            # è©±è€…æ±ºå®š
            print("ğŸ¤” [SYSTEM] æ¬¡ã®è©±è€…ã‚’æ±ºå®šä¸­...")
            next_turn = llms.get_next_speaker(history, except_names=[user_name])
            print(f"ğŸ‘‰ [SYSTEM] æ¬¡ã®è©±è€…ã¯ '{next_turn}' ã§ã™ã€‚")

            # æ¬¡ã®è©±è€…ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥
            await manager.send_json({"type": "next_speaker", "data": next_turn})

            # AIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹å§‹
            asyncio.create_task(run_ai_pipeline(next_turn))

    except WebSocketDisconnect:
        pass  # manager.disconnectã¯finallyã§å‡¦ç†
    finally:
        manager.disconnect(websocket)


async def run_ai_pipeline(turn: str):
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
    synthesis_task = asyncio.create_task(synthesis_consumer())
    audio_sender_task = asyncio.create_task(audio_sender_consumer())

    # LLMãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
    await llm_stream_producer(turn)

    # å…¨ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒçµ‚äº†ã™ã‚‹ã®ã‚’å¾…ã¤
    await synthesis_task
    await audio_sender_task
    print("ğŸ [SYSTEM] AIã®ã‚¿ãƒ¼ãƒ³å‡¦ç†ãŒã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸã€‚")


# --- é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ä¿¡è¨­å®š ---
app.mount("/frontend", StaticFiles(directory="frontend"), name="frontend")


@app.get("/")
async def read_root():
    return FileResponse("frontend/index.html")


# --- ã‚µãƒ¼ãƒãƒ¼èµ·å‹• ---
if __name__ == "__main__":
    load_config_and_init()
    uvicorn.run(app, host="0.0.0.0", port=8000)
