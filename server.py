import asyncio
import base64
import json
import logging
import traceback
from io import BytesIO

from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydub import AudioSegment

from src.app_context import AppContext
from src.logger import get_logger

load_dotenv()
logger = get_logger(__name__, level=logging.INFO)

app = FastAPI()

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
ctx: AppContext | None = None
history: list[dict] | None = None
effective_gui_mode: str = "browser_asr"

llm_text_queue = asyncio.Queue()
audio_data_queue = asyncio.Queue()


def initialize(app_context: AppContext):
    """ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã¨GUIãƒ¢ãƒ¼ãƒ‰ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    global ctx, history, effective_gui_mode
    try:
        ctx = app_context
        history = list(ctx.initial_history)
        app.mount(
            ctx.cfg.chat.image.url_path,
            StaticFiles(directory=ctx.cfg.chat.image.save_dir),
            name="images",
        )
        app.mount("/frontend", StaticFiles(directory="frontend"), name="frontend")

        base_input_mode = ctx.cfg.chat.user.input
        if base_input_mode == "ai":
            effective_gui_mode = "ai"
        else:
            asr_engine = getattr(ctx.cfg.chat.user, "asr_engine", "browser")
            if asr_engine in ["vosk", "whisper", "gemini_asr"]:
                effective_gui_mode = "server_asr"
            else:
                effective_gui_mode = "browser_asr"

        logger.info(
            f"âœ… [SYSTEM] åˆæœŸåŒ–å®Œäº† (Config Input: {base_input_mode}, Effective GUI Mode: {effective_gui_mode})"
        )

    except Exception as e:
        logger.error(f"âŒ [SYSTEM] åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()


class ConnectionManager:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def send_json(self, data: dict):
        if self.active_connections:
            try:
                await self.active_connections[0].send_json(data)
            except Exception:
                pass


manager = ConnectionManager()


def llm_stream_blocking_task(
    turn: str,
    current_history: list,
    loop: asyncio.AbstractEventLoop,
    webcam_capture: str | None = None,
):
    full_response, answer_segment = "", ""
    try:
        utter_chain = ctx.llms.get_utter_chain(current_history, webcam_capture)
        utter_prompt_vars = {"speaker": turn}
        for content in utter_chain.stream(utter_prompt_vars):
            full_response += content
            answer_segment += content
            asyncio.run_coroutine_threadsafe(
                manager.send_json(
                    {"type": "chunk", "data": {"name": turn, "content": content}}
                ),
                loop,
            )
            if (
                answer_segment
                and answer_segment[-1] in ctx.cfg.chat.streaming_voice_output
            ):
                asyncio.run_coroutine_threadsafe(
                    llm_text_queue.put((turn, answer_segment)), loop
                )
                answer_segment = ""
        if answer_segment:
            asyncio.run_coroutine_threadsafe(
                llm_text_queue.put((turn, answer_segment)), loop
            )
        return {"name": turn, "type": "text", "content": full_response}
    except Exception:
        traceback.print_exc()
        return None
    finally:
        # ç™ºè©±ã®çµ‚ã‚ã‚Šã«Noneã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦ã€éŸ³å£°å‡¦ç†ã®å®Œäº†ã‚’å¾…ã¦ã‚‹ã‚ˆã†ã«ã™ã‚‹
        asyncio.run_coroutine_threadsafe(llm_text_queue.put(None), loop)


async def synthesis_consumer():
    """(ãƒ¯ãƒ¼ã‚«ãƒ¼) llm_text_queueã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã€éŸ³å£°åˆæˆã—ã¦audio_data_queueã«æ¸¡ã™"""
    logger.info("âœ… [WORKER] Synthesis consumer started.")
    while True:
        task = await llm_text_queue.get()
        if task is None:
            await audio_data_queue.put(None)
            llm_text_queue.task_done()
            continue  # Noneã‚’å—ã‘å–ã£ã¦ã‚‚ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯çµ‚äº†ã—ãªã„

        speaker_name, text = task
        voice_config = ctx.ai_config.get(speaker_name)

        if not voice_config or not voice_config.engine:
            llm_text_queue.task_done()
            continue
        try:
            data, sr = await ctx.tts_engines[voice_config.engine].synthesize_async(
                text, **vars(voice_config.config)
            )
            if data is not None and sr is not None:
                await audio_data_queue.put((data, sr, str(data.dtype)))
        except Exception as e:
            logger.error(f"âŒ [SYNTH] éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            llm_text_queue.task_done()


async def audio_sender_consumer():
    """(ãƒ¯ãƒ¼ã‚«ãƒ¼) audio_data_queueã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ã™ã‚‹"""
    logger.info("âœ… [WORKER] Audio sender consumer started.")
    while True:
        task = await audio_data_queue.get()
        if task is None:
            audio_data_queue.task_done()
            continue  # Noneã‚’å—ã‘å–ã£ã¦ã‚‚ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯çµ‚äº†ã—ãªã„

        data, sr, dtype = task
        try:
            encoded_audio = base64.b64encode(data.tobytes()).decode("utf-8")
            await manager.send_json(
                {
                    "type": "audio",
                    "data": {"audio": encoded_audio, "samplerate": sr, "dtype": dtype},
                }
            )
        except Exception:
            pass
        finally:
            audio_data_queue.task_done()


async def image_generation_task(current_history):
    task_id = "image_gen"
    await manager.send_json(
        {
            "type": "status_update",
            "data": {"id": task_id, "text": "ğŸ¨ ç”»åƒã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."},
        }
    )
    try:
        image_url, _ = await asyncio.to_thread(
            ctx.img_generator.generate_image, current_history, ctx.cfg.chat.image.edit
        )
        if image_url:
            await manager.send_json({"type": "image", "url": image_url})
    except Exception as e:
        logger.error(f"âŒ [IMAGE] ç”»åƒç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        await manager.send_json(
            {
                "type": "status_update",
                "data": {
                    "id": f"{task_id}_error",
                    "text": "ğŸ¨ ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                },
            }
        )
        await asyncio.sleep(3)
        await manager.send_json(
            {"type": "status_remove", "data": {"id": f"{task_id}_error"}}
        )
    finally:
        await manager.send_json({"type": "status_remove", "data": {"id": task_id}})


async def main_pipeline_task(
    turn: str, loop: asyncio.AbstractEventLoop, webcam_capture: str | None = None
):
    """LLMã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œã—ã€éŸ³å£°é€ä¿¡ã®å®Œäº†ã‚’å¾…ã¤"""
    llm_task = asyncio.to_thread(
        llm_stream_blocking_task, turn, list(history), loop, webcam_capture
    )
    main_response = await llm_task
    # ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå‡¦ç†ã•ã‚Œã€éŸ³å£°ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ã‚‰ã‚Œã‚‹ã®ã‚’å¾…ã¤
    await llm_text_queue.join()
    await audio_data_queue.join()
    return main_response


async def run_single_turn(turn: str, webcam_capture: str | None = None):
    global history
    loop = asyncio.get_running_loop()
    history_len_before_turn = len(history)
    await manager.send_json({"type": "next_speaker", "data": turn})
    main_response = await main_pipeline_task(turn, loop, webcam_capture)
    await manager.send_json({"type": "utterance_end", "data": turn})
    if main_response:
        history.append(main_response)
        history_len_after_turn = len(history)
        interval = ctx.cfg.chat.image.interval
        if (history_len_before_turn // interval) < (history_len_after_turn // interval):
            asyncio.create_task(image_generation_task(list(history)))


async def conversation_flow(initial_turn: str, webcam_capture: str | None = None):
    """ä¼šè©±ã®ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ã€‚AIãƒ¢ãƒ¼ãƒ‰ã¨é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã«å¯¾å¿œã€‚"""
    turn = initial_turn
    is_ai_mode = effective_gui_mode == "ai"
    try:
        while True:
            if not is_ai_mode and turn == ctx.llmcfg.user_name:
                break
            await run_single_turn(turn, webcam_capture)
            last_speaker = turn
            turn = await asyncio.to_thread(
                ctx.turn_manager.get_next_speaker,
                list(history),
                last_speaker=last_speaker,
            )
            if is_ai_mode:
                await asyncio.sleep(1)
        if not is_ai_mode:
            await manager.send_json({"type": "conversation_end"})
    except asyncio.CancelledError:
        logger.info("ğŸ¤– [SYSTEM] Conversation flow was cancelled.")
        await manager.send_json({"type": "conversation_stopped"})
    except Exception as e:
        logger.error(f"âŒ [SYSTEM] Conversation flow error: {e}")
        traceback.print_exc()


async def process_user_audio(audio_bytes: bytes) -> str:
    try:
        audio_segment = AudioSegment.from_file(BytesIO(audio_bytes), format="webm")
        audio_segment = (
            audio_segment.set_frame_rate(16000).set_sample_width(2).set_channels(1)
        )
        pcm_audio_bytes = audio_segment.raw_data
        logger.info(f"ğŸ¤ [DECODE] éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰æˆåŠŸ: {len(pcm_audio_bytes)} bytes")
        user_message = await asyncio.to_thread(
            ctx.asr_engine.process_audio, pcm_audio_bytes
        )
        return user_message
    except Exception as e:
        logger.error(f"âŒ [ASR] éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return ""


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    global history, effective_gui_mode

    if ctx is None:
        logger.error("âŒ [SYSTEM] ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        await websocket.close(code=1011, reason="Server not initialized")
        return

    ctx.turn_manager.reset()
    history = list(ctx.initial_history)
    conversation_task = None

    # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’ã“ã“ã§èµ·å‹•ã—ã€æ¥ç¶šä¸­ã¯ãšã£ã¨å¸¸é§ã•ã›ã‚‹
    synth_task = asyncio.create_task(synthesis_consumer())
    sender_task = asyncio.create_task(audio_sender_consumer())

    await manager.send_json(
        {
            "type": "config",
            "data": {
                "user_input_mode": effective_gui_mode,
                "user_name": ctx.llmcfg.user_name,
                "character_icons": ctx.character_icons,
            },
        }
    )
    for message in history:
        text_message = {"name": message["name"], "content": message["content"]}
        if message["type"] == "image":
            text_message["content"] = "(ç”»åƒæ·»ä»˜)"
        await manager.send_json({"type": "history", "data": text_message})

    try:
        # å¸¸ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¾…ã¤ãƒ«ãƒ¼ãƒ—
        while True:
            raw_message = await websocket.receive()
            user_message_text = ""
            user_message_image = None
            webcam_capture = None

            if "bytes" in raw_message:
                if not ctx.asr_engine:
                    logger.warning(
                        "âš ï¸ [SYSTEM] ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ASRãŒç„¡åŠ¹ãªçŠ¶æ…‹ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ç„¡è¦–ã—ã¾ã™ã€‚"
                    )
                    continue
                user_message_text = await process_user_audio(raw_message["bytes"])
                if user_message_text:
                    await manager.send_json(
                        {"type": "user_transcription", "data": user_message_text}
                    )
                else:
                    logger.info(
                        "ğŸ¤ [ASR] èªè­˜çµæœãŒç©ºã®ãŸã‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ãƒªãƒˆãƒ©ã‚¤ã‚’è¦æ±‚ã—ã¾ã™ã€‚"
                    )
                    await manager.send_json({"type": "retry_audio_input"})
                    continue

            elif "text" in raw_message:
                data = json.loads(raw_message["text"])
                msg_type = data.get("type")

                if msg_type == "start_ai_conversation":
                    if effective_gui_mode == "ai":
                        logger.info(
                            "ğŸ¤– [SYSTEM] Client requested to start AI conversation."
                        )
                        if conversation_task and not conversation_task.done():
                            conversation_task.cancel()
                        initial_turn = ctx.initial_turn
                        conversation_task = asyncio.create_task(
                            conversation_flow(initial_turn)
                        )
                    continue

                elif msg_type == "stop_ai_conversation":
                    if conversation_task and not conversation_task.done():
                        logger.info(
                            "ğŸ¤– [SYSTEM] AI conversation stop requested by client."
                        )
                        conversation_task.cancel()
                    continue

                user_message_text = data.get("text", "")
                user_message_image = data.get("image")
                webcam_capture = data.get("webcam_capture")

            if not user_message_text and not user_message_image and not webcam_capture:
                continue

            user_name = ctx.llmcfg.user_name
            if user_message_text:
                history.append(
                    {"name": user_name, "type": "text", "content": user_message_text}
                )
            if user_message_image:
                history.append(
                    {"name": user_name, "type": "image", "content": user_message_image}
                )

            next_turn = await asyncio.to_thread(
                ctx.turn_manager.get_next_speaker, list(history), last_speaker=user_name
            )
            if conversation_task and not conversation_task.done():
                conversation_task.cancel()
            conversation_task = asyncio.create_task(
                conversation_flow(next_turn, webcam_capture)
            )

    except WebSocketDisconnect:
        logger.info("ğŸ‘‹ [SYSTEM] ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"âŒ [SYSTEM] WebSocketãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
    finally:
        logger.info("Cancelling worker and conversation tasks...")
        if conversation_task and not conversation_task.done():
            conversation_task.cancel()
        synth_task.cancel()
        sender_task.cancel()
        await asyncio.gather(
            conversation_task, synth_task, sender_task, return_exceptions=True
        )
        logger.info("All tasks cancelled.")
        manager.disconnect(websocket)


@app.get("/")
async def read_root():
    return FileResponse("frontend/index.html")
