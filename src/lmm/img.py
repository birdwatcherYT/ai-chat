import os
import time
from dotenv import load_dotenv
from PIL import Image
from io import BytesIO

load_dotenv()

from google import genai
from google.genai import types
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser

from .common import history_to_text
from .common import LLMConfig

class ImageGenerator:
    def __init__(self, llmcfg: LLMConfig, save_dir: str, url_path: str):
        self.llmcfg = llmcfg
        self.save_dir = save_dir
        self.url_path = url_path
        # mockãŒTrueã§ãªã„å ´åˆã®ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if not self.llmcfg.image.get("mock", False):
            self.client = genai.Client()
        else:
            self.client = None
        self.llm = ChatGoogleGenerativeAI(**llmcfg.gemini)
        self.situation_chain = self.get_situation_chain()
        self.last_image: Image.Image = None

    def get_situation_chain(self):
        prompt = PromptTemplate.from_template(
            """**ä¼šè©±å±¥æ­´**ã‚’å…ƒã«ä»Šã®çŠ¶æ³ã‚’è¡¨ã™èª¬æ˜ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€å‡ºåŠ›ã«ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’å«ã‚ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚ã“ã®å‡ºåŠ›ã¯ç”»åƒç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±
{user_name}
{user_character}
{chara_prompt}
# ä¼šè©±å±¥æ­´```json
{messages}
```
""",
            partial_variables={
                "user_name": self.llmcfg.user_name,
                "user_character": self.llmcfg.user_character,
                "chara_prompt": self.llmcfg.chara_prompt,
            },
        )
        return prompt | self.llm | StrOutputParser()

    def _generate_image(self, prompt: str, image: Image.Image = None) -> str | None:
        print(f"ğŸ¨ [IMAGE] ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}...")
        try:
            # clientãŒNoneã®å ´åˆã¯APIã‚’å‘¼ã°ãªã„
            if self.client is None:
                raise ValueError("Client is not initialized in mock mode.")

            response = self.client.models.generate_content(
                model=self.llmcfg.image.model,
                contents=[prompt, image] if image else prompt,
                config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"]),
            )
            for part in response.candidates[0].content.parts:
                if part.inline_data is not None:
                    new_image = Image.open(BytesIO(part.inline_data.data))
                    self.last_image = new_image
                    filename = f"{int(time.time())}.png"
                    save_path = os.path.join(self.save_dir, filename)
                    image_url = f"{self.url_path}/{filename}"
                    new_image.save(save_path)
                    print(f"ğŸ–¼ï¸ [IMAGE] ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
                    return image_url
        except Exception as e:
            print(f"âŒ [IMAGE] ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

    def generate_image(self, history: list[dict[str, str]], edit: bool = False) -> str | None:
        """çŠ¶æ³ã‚’åˆ¤æ–­ã—ã€ç”»åƒã‚’ç”Ÿæˆã—ã¦URLã‚’è¿”ã™ã€‚ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’è€ƒæ…®ã€‚"""
        if self.llmcfg.image.mock:
            print("ğŸ–¼ï¸ [MOCK-IMAGE] Mocking image generation.")
            time.sleep(3) # ãƒªã‚¢ãƒ«ãªå¾…æ©Ÿæ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            # placehold.jp ã¯æ—¥æœ¬èªã‚‚ä½¿ãˆã‚‹
            return "https://placehold.jp/3d4070/ffffff/512x512.png?text=ãƒ¢ãƒƒã‚¯ç”»åƒ"

        situation = self.situation_chain.invoke({"messages": history_to_text(history)})
        print("-" * 20, "çŠ¶æ³èª¬æ˜", "-" * 20, "\n", situation, "\n", "-" * 20)
        
        if edit and self.last_image:
            prompt = f"ç¾åœ¨ã®ç”»åƒã‹ã‚‰æ¬¡ã®çŠ¶æ³ã‚’è¡¨ã™ã‚¢ãƒ‹ãƒ¡é¢¨ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:\n{situation}"
            return self._generate_image(prompt, self.last_image)
        else:
            prompt = f"æ¬¡ã®çŠ¶æ³ã‚’è¡¨ã™ã‚¢ãƒ‹ãƒ¡é¢¨ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:\n{situation}"
            return self._generate_image(prompt)
